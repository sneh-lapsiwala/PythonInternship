# ü´Ä Heart Disease Prediction with Decision Trees and Random Forests

This project demonstrates the application of Decision Trees and Random Forests for predicting the presence of heart disease based on patient data. The goal is to build interpretable models and analyze feature importances.

## ‚ú® Features

-   **Data Loading & Exploration:** Loading the dataset and performing basic exploratory data analysis (EDA) including checking for missing values and visualizing feature correlations.
-   **Data Preprocessing:** Separating features and target variable, and splitting the data into training and testing sets.
-   **Decision Tree Classifier:** Training and evaluating a Decision Tree model.
-   **Overfitting Analysis:** Visualizing the effect of tree depth on model performance and identifying potential overfitting.
-   **Random Forest Classifier:** Training and evaluating a Random Forest model.
-   **Feature Importance:** Identifying the most influential features for prediction using the Random Forest model.
-   **Cross-Validation:** Evaluating model stability using Stratified K-Fold Cross-Validation.
-   **Model Visualization:** Visualizing the trained Decision Tree.

## üì¶ Requirements

To run this notebook, you need the following libraries installed:

-   `pandas`
-   `numpy`
-   `matplotlib`
-   `seaborn`
-   `scikit-learn`

You can install them using pip:         

This notebook is designed to be run in a **Jupyter Notebook** or **Google Colab** environment, as it uses `google.colab.files` for dataset upload.

## üèÉ How to Run

1.  Clone the repository (if applicable) or download the notebook file (`.ipynb`).
2.  Ensure you have the required libraries installed.
3.  Open the notebook in your Jupyter environment (e.g., JupyterLab, VS Code with Python extension, Google Colab).
4.  Execute the cells sequentially. The notebook includes a section to upload the dataset file (`data.csv` or `data (2).csv` as mentioned in the notebook) if running in Google Colab.

## üìä Dataset

The dataset contains information about patients with various attributes like age, sex, chest pain type, blood pressure, cholesterol, etc. The target variable is `target`, indicating the presence (1) or absence (0) of heart disease.

*(Self-correction: Add dataset source citation here if you have one)*
*Example: The dataset is obtained from the UCI Machine Learning Repository [Link to dataset page if available].*

## üìà Analysis Summary

The analysis covers:

-   Initial data inspection and correlation analysis, highlighting features strongly related to the target variable (e.g., `cp`, `thalach`, `slope`).
-   Training a Decision Tree classifier and analyzing its performance and structure.
-   Investigating the impact of `max_depth` on Decision Tree accuracy and identifying overfitting.
-   Training a Random Forest classifier, which typically shows improved performance compared to a single Decision Tree due to ensemble averaging.
-   Identifying key features driving the Random Forest predictions (e.g., `cp`, `thalach`, `oldpeak`, `ca`).
-   Cross-validation results showing the average performance and variability of both models.

## üí° Conclusion

Decision Trees offer interpretability, while Random Forests provide better accuracy and generalization by reducing overfitting. Key predictors identified include chest pain type, maximum heart rate achieved, and ST depression induced by exercise. Further improvements could involve hyperparameter tuning, exploring other features, or trying more advanced ensemble methods.

*(Self-correction: Update the model comparison table with actual accuracy values from your notebook output)*
*Example:*
*| Model           | Accuracy (Test Set) | CV Accuracy*
*|----------------|--------------------|------------|*
*| Decision Tree  | ~X.XX              | ~Y.YY ¬± Z.ZZ |*
*| Random Forest  | ~A.AA              | ~B.BB ¬± C.CC |*

---

*This README is generated based on the content of the provided Jupyter notebook.*
